{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark: Koalas (PySpark) and Dask - Data Preparation\n",
    "The benchmark was performed against the 2009 - 2013 Yellow Taxi Trip Records (157 GB) from NYC Taxi and Limousine Commission (TLC) Trip Record Data.\n",
    "\n",
    "The CSV files were downloaded into Databricks File System (DBFS), and then were converted into Parquet files via Koalas for better efficiency.\n",
    "\n",
    "Download url: https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page.\n",
    "\n",
    "Data dictionary: https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf.\n",
    "\n",
    "The scenario used in this benchmark was inspired by https://github.com/xdssio/big_data_benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CSV files to DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh mkdir -p /dbfs/FileStore/taxi_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh ls /dbfs/FileStore/taxi_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_loc = {} # Map download url to the file location in DBFS\n",
    " \n",
    "for year in range(2009, 2014):\n",
    "  for m in range(1, 13):\n",
    "    month = \"{:02d}\".format(m)\n",
    "    fname = 'yellow_tripdata_%s-%s.csv' % (year, month)\n",
    "    url = 'https://s3.amazonaws.com/nyc-tlc/trip+data/%s' % fname\n",
    "    loc = '/dbfs/FileStore/taxi_csv/%s' % fname\n",
    "    url_loc[url] = loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tqdm\n",
    "\n",
    "for url, loc in tqdm.tqdm(url_loc.items()):\n",
    "  urllib.request.urlretrieve(url, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh ls /dbfs/FileStore/taxi_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bytes = 0\n",
    "for fileInfo in dbutils.fs.ls('FileStore/taxi_csv'):\n",
    "  total_bytes += fileInfo.size\n",
    "print('%s GBs data in total' % (total_bytes * 1e-9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Parquet files\n",
    "Convert downloaded CSV files into Parquet files via Koalas for better efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import databricks.koalas as ks\n",
    " \n",
    "ks.set_option('compute.default_index_type', 'distributed-sequence') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {\n",
    "  'Passenger_Count': 'int64', \n",
    "  'Start_Lon': 'float64', \n",
    "  'Start_Lat': 'float64',\n",
    "  'End_Lon': 'float64', \n",
    "  'End_Lat': 'float64', \n",
    "  'Fare_Amt': 'float64', \n",
    "  'Tip_Amt': 'float64', \n",
    "  'Tolls_Amt': 'float64',\n",
    "  'Total_Amt': 'float64'\n",
    "}\n",
    "ks_df= ks.read_csv('/FileStore/taxi_csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df.columns = ks_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh rm -fr /dbfs/FileStore/ks_taxi_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df.to_parquet('FileStore/ks_taxi_parquet', index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bytes = 0\n",
    "for file_info in dbutils.fs.ls('FileStore/ks_taxi_parquet'):\n",
    "  total_bytes += file_info.size\n",
    "print('%s GBs data in total' % (total_bytes * 1e-9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Filtering Size\n",
    "(Size of filtered data / Size of total data) in the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import databricks.koalas as ks\n",
    "koalas_data = ks.read_parquet('/FileStore/ks_taxi_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (koalas_data.tip_amt >= 1) & (koalas_data.tip_amt <= 5)\n",
    " \n",
    "print(f'In the benchmark, filtered data is {len(koalas_data[expr_filter]) / len(koalas_data) * 100}% of total data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
