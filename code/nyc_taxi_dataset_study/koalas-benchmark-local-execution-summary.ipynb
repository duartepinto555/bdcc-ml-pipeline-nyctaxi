{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# Benchmark: Koalas (PySpark) and Dask - Local execution summary\n",
    "The benchmark was performed against the 2009 - 2013 Yellow Taxi Trip Records (157 GB) from NYC Taxi and Limousine Commission (TLC) Trip Record Data.\n",
    "\n",
    "The benchmark results below explain the performance differences between Koalas and Dask. Because the Koalas APIs are written on the top of PySpark, the results of this benchmark would apply similarly to PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    " \n",
    "def fair_avg(durations):\n",
    "  \"\"\"Get an average duration among multiple durations fairly by removing the first run and the best run first.\"\"\"\n",
    "  durations = durations[1:] \n",
    "  durations.remove(min(durations))\n",
    "  return sum(durations) / len(durations)\n",
    " \n",
    "def rename_index(df):\n",
    "  \"\"\"Rename operations in the average result dataframe for clarity.\"\"\"\n",
    "  df.index = map(\n",
    "    lambda s: s.replace(\"filtered \", \"\")\n",
    "      .replace(\"of columns\", \"of series\")\n",
    "      .replace(\"addition of series\", \"series addition\")\n",
    "      .replace(\"multiplication of series\", \"series multiplication\")\n",
    "      .replace(\"arithmetic ops\", \"arithmetic\")\n",
    "      .replace(\"count index length\", \"count index\"),\n",
    "    df.index)\n",
    "  return df\n",
    " \n",
    "def avg_result_df(file_name_prefix):\n",
    "  \"\"\"Get result files with the given prefix and then construct the average result dataframe.\"\"\"\n",
    "  dfs = []\n",
    "  file_infos = os.listdir(f'{DATASETS_DIR}/../results/koalas-benchmark-no-parquet-cache')\n",
    "  for file_info in file_infos:\n",
    "    if file_info.startswith(file_name_prefix):\n",
    "      dfs.append(pd.read_parquet(f'{DATASETS_DIR}/../results/koalas-benchmark-no-parquet-cache/%s' % file_info))\n",
    "  print(f'{file_name_prefix} has {len(dfs)} runs')    \n",
    "  \n",
    "  avg_df = dfs[0].copy()\n",
    "  for op in dfs[0].index:\n",
    "    for lib in ['koalas', 'dask']:\n",
    "      durations = []\n",
    "      for df in dfs:\n",
    "        durations.append(df.loc[op][lib])\n",
    "      avg_df.loc[op][lib] = fair_avg(durations)\n",
    "      \n",
    "  return rename_index(avg_df)\n",
    " \n",
    "def annotate(ax):\n",
    "  \"\"\"Annotate the height of each bar in the plot.\"\"\"\n",
    "  for p in ax.patches:\n",
    "    ax.annotate(\"%.2fs\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    " \n",
    "def annotate_x_times_faster(ax, x_times_list):\n",
    "  \"\"\"Annotate Koalas is how many times faster per operation in the plot.\"\"\"\n",
    "  num_ops = len(x_times_list)\n",
    "  for i, p in enumerate(ax.patches):\n",
    "    if i < num_ops:  # The first half of ax.patches of Koalas; we only annotate Koalas patches\n",
    "      ax.annotate(\"%.1fx\" % x_times_list[i], (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(4, 10), textcoords='offset points', fontsize=8, weight='bold', color=\"#585858\")\n",
    " \n",
    "local_res_df = avg_result_df('single_node_')\n",
    "local_res_df.columns = ['Koalas (PySpark)', 'Dask']\n",
    "standard_ops = local_res_df.iloc[:15]\n",
    "ops_with_filtering = local_res_df.iloc[15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = 'Standard operations (local execution)'\n",
    " \n",
    "ax = standard_ops.sort_index().plot.bar(title=plot_title)\n",
    "ax.set_ylabel(\"Elapsed time (sec)\")\n",
    " \n",
    "tmp_df_x_times_faster = standard_ops.sort_index().copy()\n",
    "tmp_df_x_times_faster['Dask / Koalas'] = tmp_df_x_times_faster.Dask / tmp_df_x_times_faster['Koalas (PySpark)']\n",
    "tmp_df_x_times_faster['Koalas / Dask'] = tmp_df_x_times_faster['Koalas (PySpark)'] / tmp_df_x_times_faster.Dask\n",
    "annotate_x_times_faster(ax, x_times_list=tmp_df_x_times_faster['Dask / Koalas'].to_list())\n",
    " \n",
    "standard_ops.sort_index().plot.bar(logy=True, title='%s - log scaling' % plot_title).set_ylabel(\"Elapsed time (sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_x_times_faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(pd.Series(stats.gmean(standard_ops), index=['Koalas (PySpark)', 'Dask']).plot.bar(title='Geometric mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(standard_ops.sum().plot.bar(title='Total execution time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance diff %% (simple avg): %s\" % (sum(standard_ops.Dask / standard_ops['Koalas (PySpark)']) / len(standard_ops)))\n",
    "print(\"Performance diff %% (geomean): %s\" % stats.gmean(standard_ops.Dask / standard_ops['Koalas (PySpark)']))\n",
    " \n",
    "arithmetic_ops = standard_ops.filter(items=['complex arithmetic', 'series multiplication', 'series addition'], axis=0)\n",
    "print(\"Performance diff (arthemetic) %% (simple avg): %s\" % (sum(arithmetic_ops.Dask / arithmetic_ops['Koalas (PySpark)']) / len(arithmetic_ops)))\n",
    "print(\"Performance diff (arthemetic) %% (geomean): %s\" % stats.gmean(arithmetic_ops.Dask / arithmetic_ops['Koalas (PySpark)']))\n",
    " \n",
    "basic_stats_ops = standard_ops.filter(items=['count', 'mean', 'standard deviation', 'count index', 'join', 'join count'], axis=0)\n",
    "print(\"Performance diff (basic stats) %% (simple avg): %s\" % (sum(basic_stats_ops.Dask / basic_stats_ops['Koalas (PySpark)']) / len(basic_stats_ops)))\n",
    "print(\"Performance diff (basic stats) %% (geomean): %s\" % stats.gmean(basic_stats_ops.Dask / basic_stats_ops['Koalas (PySpark)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = 'Operations with filtering (local execution)'\n",
    " \n",
    "ax = ops_with_filtering.sort_index().plot.bar(title=plot_title)\n",
    "ax.set_ylabel(\"Elapsed time (sec)\")\n",
    " \n",
    "tmp_df_x_times_faster = ops_with_filtering.sort_index().copy()\n",
    "tmp_df_x_times_faster['Dask / Koalas'] = tmp_df_x_times_faster.Dask / tmp_df_x_times_faster['Koalas (PySpark)']\n",
    "tmp_df_x_times_faster['Koalas / Dask'] = tmp_df_x_times_faster['Koalas (PySpark)'] / tmp_df_x_times_faster.Dask\n",
    "annotate_x_times_faster(ax, x_times_list=tmp_df_x_times_faster['Dask / Koalas'].to_list())\n",
    " \n",
    "ops_with_filtering.sort_index().plot.bar(logy=True, title='%s - log scaling' % plot_title).set_ylabel(\"Elapsed time (sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_x_times_faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(pd.Series(stats.gmean(ops_with_filtering), index=['Koalas (PySpark)', 'Dask']).plot.bar(title='Geometric mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(ops_with_filtering.sum().plot.bar(title='Total execution time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance diff %% (simple avg): %s\" % (sum(ops_with_filtering.Dask / ops_with_filtering['Koalas (PySpark)']) / len(ops_with_filtering)))\n",
    "print(\"Performance diff %% (geomean): %s\" % stats.gmean(ops_with_filtering.Dask / ops_with_filtering['Koalas (PySpark)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.concat([standard_ops, ops_with_filtering])\n",
    "print(\"Total performance diff %% (simple avg): %s\" % (sum(overall_df.Dask / overall_df['Koalas (PySpark)']) / len(overall_df)))\n",
    "print(\"Total performance diff %% (geomean): %s\" % stats.gmean(overall_df.Dask / overall_df['Koalas (PySpark)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
