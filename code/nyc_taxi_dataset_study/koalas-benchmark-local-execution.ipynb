{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# Benchmark: Koalas (PySpark) and Dask - Local execution\n",
    "The benchmark was performed against the 2009 - 2013 Yellow Taxi Trip Records (157 GB) from NYC Taxi and Limousine Commission (TLC) Trip Record Data. We identified common operations from our pandas workloads such as basic calculations of statistics, join, filtering and grouping on this dataset.\n",
    "\n",
    "The operations were measured with/without filter operations to consider real world workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.databricks.io.cache.enabled is false\n",
      "Access spark session: http://localhost:4040 <pyspark.sql.session.SparkSession object at 0x000001908C9FCD88>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize the Spark session (if not already initialized)\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"bdcc\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "#     .config(\"spark.executor.memory\", \"10g\") \\\n",
    "#     .config(\"spark.executor.instances\", \"2\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"bdcc\") \\\n",
    "#     .config(\"spark.executor.memory\", \"4g\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "#     .config(\"spark.driver.memory\", \"20g\") \\\n",
    "#     .config(\"spark.driver.cores\", \"4\") \\\n",
    "#     .config('PYSPARK_PYTHON', 'python') \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"bdcc\") \\\n",
    "    .master(\"local[6]\") \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.cores\", \"6\") \\\n",
    "    .config(\"spark.driver.cores\", '1') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"false\")\n",
    "print(\"spark.databricks.io.cache.enabled is %s\" % spark.conf.get(\"spark.databricks.io.cache.enabled\"))\n",
    "print(\"Access spark session: http://localhost:4040 %s\" % spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U koalas dask[complete] numpy pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.1.5\n",
      "numpy version: 1.19.5\n",
      "koalas version: 1.7.0\n",
      "dask version: 2021.03.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    " \n",
    "print('pandas version: %s' % pd.__version__)\n",
    "print('numpy version: %s' % np.__version__)\n",
    "print('koalas version: %s' % ks.__version__)\n",
    "import dask\n",
    "print('dask version: %s' % dask.__version__)\n",
    " \n",
    "import time\n",
    "\n",
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    \"\"\"Benchmark the given function against the given DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function to benchmark\n",
    "    df: data frame\n",
    "    benchmarks: container for benchmark results\n",
    "    name: task name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Duration (in seconds) of the given operation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "    return benchmarks['duration'][-1]\n",
    " \n",
    "def get_results(benchmarks):\n",
    "    \"\"\"Return a pandas DataFrame containing benchmark results.\"\"\"\n",
    "    return pd.DataFrame.from_dict(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:61288</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>21.47 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:61288' processes=1 threads=4, memory=21.47 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=1, threads_per_worker=4, memory_limit='20GiB') # Memory limit is set per worker\n",
    "client = Client(cluster)\n",
    "\n",
    "DATASETS_DIR = '../../datasets'\n",
    "dask_data = dd.read_parquet(f'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "\n",
    "dask_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return dd.read_parquet(f'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "  \n",
    "def count(df=None):\n",
    "    return len(df)\n",
    " \n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    " \n",
    "def mean(df):\n",
    "    return df.fare_amt.mean().compute()\n",
    " \n",
    "def standard_deviation(df):\n",
    "    return df.fare_amt.std().compute()\n",
    " \n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amt + df.tip_amt).mean().compute()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def sum_columns(df):\n",
    "#     return (df.fare_amt + df.tip_amt).compute()\n",
    " \n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amt * df.tip_amt).mean().compute()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def product_columns(df):\n",
    "#     return (df.fare_amt * df.tip_amt).compute()\n",
    "  \n",
    "def value_counts(df):\n",
    "    return df.fare_amt.value_counts().compute()\n",
    "  \n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret.mean().compute()\n",
    "  \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def complicated_arithmetic_operation(df):\n",
    "#     theta_1 = df.start_lon\n",
    "#     phi_1 = df.start_lat\n",
    "#     theta_2 = df.end_lon\n",
    "#     phi_2 = df.end_lat\n",
    "#     temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "#            + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "#     ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "#     return ret.compute()\n",
    "  \n",
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amt': ['mean', 'std'], \n",
    "        'tip_amt': ['mean', 'std']\n",
    "      }\n",
    "    ).compute()\n",
    "  \n",
    "other = groupby_statistics(dask_data)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    " \n",
    "def join_count(df, other):\n",
    "    return len(dd.merge(df, other, left_index=True, right_index=True))\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "def join_data(df, other):\n",
    "    return dd.merge(df, other, left_index=True, right_index=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file took: 0.012467145919799805 seconds\n",
      "count took: 3.402935266494751 seconds\n",
      "count index length took: 21.7066810131073 seconds\n",
      "mean took: 4.680126428604126 seconds\n",
      "standard deviation took: 6.021027326583862 seconds\n",
      "mean of columns addition took: 6.579668283462524 seconds\n",
      "mean of columns multiplication took: 6.468385934829712 seconds\n",
      "value counts took: 4.679720878601074 seconds\n",
      "mean of complex arithmetic ops took: 20.302884340286255 seconds\n",
      "groupby statistics took: 25.221879243850708 seconds\n",
      "join count took: 29.049068927764893 seconds\n",
      "join took: 25.331951141357422 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.331951141357422"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=dask_benchmarks, name='read file')\n",
    "benchmark(count, df=dask_data, benchmarks=dask_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=dask_data, benchmarks=dask_benchmarks, name='count index length')\n",
    "benchmark(mean, df=dask_data, benchmarks=dask_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=dask_data, benchmarks=dask_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns addition')\n",
    "# benchmark(sum_columns, df=dask_data, benchmarks=dask_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns multiplication')\n",
    "# benchmark(product_columns, df=dask_data, benchmarks=dask_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=dask_data, benchmarks=dask_benchmarks, name='value counts')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=dask_data, benchmarks=dask_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, dask_data, benchmarks=dask_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, dask_data, benchmarks=dask_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (dask_data.tip_amt >= 1) & (dask_data.tip_amt <= 5)\n",
    " \n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "  \n",
    "dask_filtered = filter_data(dask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 25.656850814819336 seconds\n",
      "filtered count index length took: 24.860188961029053 seconds\n",
      "filtered mean took: 26.241296768188477 seconds\n",
      "filtered standard deviation took: 26.413559198379517 seconds\n",
      "filtered mean of columns addition took: 25.802118062973022 seconds\n",
      "filtered mean of columns multiplication took: 25.537301540374756 seconds\n",
      "filtered mean of complex arithmetic ops took: 29.425952196121216 seconds\n",
      "filtered value counts took: 25.944531202316284 seconds\n",
      "filtered groupby statistics took: 27.237637758255005 seconds\n",
      "filtered join count took: 27.612762451171875 seconds\n",
      "filtered join took: 27.089094638824463 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.089094638824463"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, dask_filtered, benchmarks=dask_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_filtered, benchmarks=dask_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_filtered, benchmarks=dask_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns addition')\n",
    "# benchmark(sum_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns multiplication')\n",
    "# benchmark(product_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_filtered, benchmarks=dask_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_filtered, benchmarks=dask_benchmarks, name='filtered groupby statistics')\n",
    " \n",
    "other = groupby_statistics(dask_filtered)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    " \n",
    "benchmark(join_count, dask_filtered, benchmarks=dask_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, dask_filtered, benchmarks=dask_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:61288</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>21.47 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:61288' processes=1 threads=4, memory=21.47 GB>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "koalas_data = ks.read_parquet(F'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "\n",
    "koalas_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return ks.read_parquet(f'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "  \n",
    "def count(df=None):\n",
    "    return len(df)\n",
    " \n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    " \n",
    "def mean(df):\n",
    "    return df.fare_amt.mean()\n",
    " \n",
    "def standard_deviation(df):\n",
    "    return df.fare_amt.std()\n",
    " \n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amt + df.tip_amt).mean()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def sum_columns(df):\n",
    "#     x = df.fare_amt + df.tip_amt\n",
    "#     x.to_pandas()\n",
    "#     return x\n",
    " \n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amt * df.tip_amt).mean()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def product_columns(df):\n",
    "#     x = df.fare_amt * df.tip_amt\n",
    "#     x.to_pandas()\n",
    "#     return x\n",
    " \n",
    "def value_counts(df):\n",
    "    val_counts = df.fare_amt.value_counts()\n",
    "    val_counts.to_pandas()\n",
    "    return val_counts\n",
    "  \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def complicated_arithmetic_operation(df):\n",
    "#     theta_1 = df.start_lon\n",
    "#     phi_1 = df.start_lat\n",
    "#     theta_2 = df.end_lon\n",
    "#     phi_2 = df.end_lat\n",
    "#     temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "#            + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "#     ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2)\n",
    "#     ret.to_pandas()\n",
    "#     return ret\n",
    "  \n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2) \n",
    "    return ret.mean()\n",
    "  \n",
    "def groupby_statistics(df):\n",
    "    gb = df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amt': ['mean', 'std'], \n",
    "        'tip_amt': ['mean', 'std']\n",
    "      }\n",
    "    )\n",
    "    gb.to_pandas()\n",
    "    return gb\n",
    "  \n",
    "other = ks.DataFrame(groupby_statistics(koalas_data).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    " \n",
    "# The \"other.spark.hint('broadcast')\" requires the environment variable PYSPARK_PYTHON=python for it to work\n",
    "# issue: https://stackoverflow.com/questions/53252181/python-worker-failed-to-connect-back\n",
    "def join_count(df, other):\n",
    "    res = df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True)\n",
    "    return res.shape[0]\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "def join_data(df, other):\n",
    "    ret = df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True)\n",
    "    ret.to_pandas()\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file took: 0.20592594146728516 seconds\n",
      "count took: 0.4872777462005615 seconds\n",
      "count index length took: 0.3835182189941406 seconds\n",
      "mean took: 0.7849950790405273 seconds\n",
      "standard deviation took: 1.1820640563964844 seconds\n",
      "mean of columns addition took: 1.2565875053405762 seconds\n",
      "mean of columns multiplication took: 1.2703442573547363 seconds\n",
      "value counts took: 10.476154088973999 seconds\n",
      "mean of complex arithmetic ops took: 21.048777103424072 seconds\n",
      "groupby statistics took: 5.161369323730469 seconds\n",
      "join count took: 197.5554277896881 seconds\n",
      "join took: 374.29529333114624 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "374.29529333114624"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=koalas_benchmarks, name='read file')\n",
    "benchmark(count, df=koalas_data, benchmarks=koalas_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=koalas_data, benchmarks=koalas_benchmarks, name='count index length')\n",
    "benchmark(mean, df=koalas_data, benchmarks=koalas_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=koalas_data, benchmarks=koalas_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns addition')\n",
    "# benchmark(sum_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns multiplication')\n",
    "# benchmark(product_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=koalas_data, benchmarks=koalas_benchmarks, name='value counts')\n",
    "# benchmark(complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=koalas_data, benchmarks=koalas_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, koalas_data, benchmarks=koalas_benchmarks, name='join count', other=other)    # For this one to work, the environment variable \"PYSPARK_PYTHON\" must be set to \"python\"\n",
    "benchmark(join_data, koalas_data, benchmarks=koalas_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (koalas_data.tip_amt >= 1) & (koalas_data.tip_amt <= 5)\n",
    " \n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    " \n",
    "koalas_filtered = filter_data(koalas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 1.3020622730255127 seconds\n",
      "filtered count index length took: 0.9751574993133545 seconds\n",
      "filtered mean took: 1.5368273258209229 seconds\n",
      "filtered standard deviation took: 1.6064865589141846 seconds\n",
      "filtered mean of columns addition took: 1.440826177597046 seconds\n",
      "filtered mean of columns multiplication took: 1.4657783508300781 seconds\n",
      "filtered mean of complex arithmetic ops took: 10.1757173538208 seconds\n",
      "filtered value counts took: 8.297699451446533 seconds\n",
      "filtered groupby statistics took: 3.2496275901794434 seconds\n",
      "filtered join count took: 183.7692358493805 seconds\n",
      "filtered join took: 401.5474445819855 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "401.5474445819855"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns addition')\n",
    "# benchmark(sum_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns multiplication')\n",
    "# benchmark(product_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered groupby statistics')\n",
    " \n",
    "other = ks.DataFrame(groupby_statistics(koalas_filtered).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "benchmark(join_count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "koalas_res_temp = get_results(koalas_benchmarks).set_index('task')\n",
    "dask_res_temp = get_results(dask_benchmarks).set_index('task')\n",
    "df = pd.concat([koalas_res_temp.duration, dask_res_temp.duration], axis=1, keys=['koalas', 'dask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../datasets/../results/koalas-benchmark-no-parquet-cache/single_node_162240\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    " \n",
    "filename = f'{DATASETS_DIR}/../results/koalas-benchmark-no-parquet-cache/single_node_' + datetime.now().strftime(\"%H%M%S\")\n",
    "print(filename)\n",
    " \n",
    "df.to_parquet(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
