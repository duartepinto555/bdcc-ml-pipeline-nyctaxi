{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# Benchmark: Koalas (PySpark) and Dask - Local execution\n",
    "The benchmark was performed against the 2009 - 2013 Yellow Taxi Trip Records (157 GB) from NYC Taxi and Limousine Commission (TLC) Trip Record Data. We identified common operations from our pandas workloads such as basic calculations of statistics, join, filtering and grouping on this dataset.\n",
    "\n",
    "The operations were measured with/without filter operations to consider real world workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.databricks.io.cache.enabled is false\n",
      "Access spark session: http://localhost:4040 <pyspark.sql.session.SparkSession object at 0x000001DEB3A3F4C8>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize the Spark session (if not already initialized)\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"bdcc\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "#     .config(\"spark.executor.memory\", \"10g\") \\\n",
    "#     .config(\"spark.executor.instances\", \"2\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"bdcc\") \\\n",
    "#     .config(\"spark.executor.memory\", \"4g\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "#     .config(\"spark.driver.memory\", \"20g\") \\\n",
    "#     .config(\"spark.driver.cores\", \"4\") \\\n",
    "#     .config('PYSPARK_PYTHON', 'python') \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"bdcc\") \\\n",
    "    .master(\"local[6]\") \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.cores\", \"6\") \\\n",
    "    .config(\"spark.driver.cores\", '1') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"false\")\n",
    "print(\"spark.databricks.io.cache.enabled is %s\" % spark.conf.get(\"spark.databricks.io.cache.enabled\"))\n",
    "print(\"Access spark session: http://localhost:4040 %s\" % spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U koalas dask[complete] numpy pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.1.5\n",
      "numpy version: 1.19.5\n",
      "koalas version: 1.7.0\n",
      "dask version: 2021.03.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    " \n",
    "print('pandas version: %s' % pd.__version__)\n",
    "print('numpy version: %s' % np.__version__)\n",
    "print('koalas version: %s' % ks.__version__)\n",
    "import dask\n",
    "print('dask version: %s' % dask.__version__)\n",
    " \n",
    "import time\n",
    "\n",
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    \"\"\"Benchmark the given function against the given DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function to benchmark\n",
    "    df: data frame\n",
    "    benchmarks: container for benchmark results\n",
    "    name: task name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Duration (in seconds) of the given operation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "    return benchmarks['duration'][-1]\n",
    " \n",
    "def get_results(benchmarks):\n",
    "    \"\"\"Return a pandas DataFrame containing benchmark results.\"\"\"\n",
    "    return pd.DataFrame.from_dict(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:55849</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>21.47 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55849' processes=1 threads=4, memory=21.47 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=1, threads_per_worker=4, memory_limit='20GiB') # Memory limit is set per worker\n",
    "client = Client(cluster)\n",
    "\n",
    "DATASETS_DIR = '../../datasets'\n",
    "dask_data = dd.read_parquet(f'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "\n",
    "dask_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return dd.read_parquet(f'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "  \n",
    "def count(df=None):\n",
    "    return len(df)\n",
    " \n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    " \n",
    "def mean(df):\n",
    "    return df.fare_amt.mean().compute()\n",
    " \n",
    "def standard_deviation(df):\n",
    "    return df.fare_amt.std().compute()\n",
    " \n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amt + df.tip_amt).mean().compute()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def sum_columns(df):\n",
    "#     return (df.fare_amt + df.tip_amt).compute()\n",
    " \n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amt * df.tip_amt).mean().compute()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def product_columns(df):\n",
    "#     return (df.fare_amt * df.tip_amt).compute()\n",
    "  \n",
    "def value_counts(df):\n",
    "    return df.fare_amt.value_counts().compute()\n",
    "  \n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret.mean().compute()\n",
    "  \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def complicated_arithmetic_operation(df):\n",
    "#     theta_1 = df.start_lon\n",
    "#     phi_1 = df.start_lat\n",
    "#     theta_2 = df.end_lon\n",
    "#     phi_2 = df.end_lat\n",
    "#     temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "#            + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "#     ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "#     return ret.compute()\n",
    "  \n",
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amt': ['mean', 'std'], \n",
    "        'tip_amt': ['mean', 'std']\n",
    "      }\n",
    "    ).compute()\n",
    "  \n",
    "other = groupby_statistics(dask_data)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    " \n",
    "def join_count(df, other):\n",
    "    return len(dd.merge(df, other, left_index=True, right_index=True))\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "def join_data(df, other):\n",
    "    return dd.merge(df, other, left_index=True, right_index=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file took: 0.008478641510009766 seconds\n",
      "count took: 3.315784454345703 seconds\n",
      "count index length took: 20.070648908615112 seconds\n",
      "mean took: 4.278668165206909 seconds\n",
      "standard deviation took: 5.791538715362549 seconds\n",
      "mean of columns addition took: 5.865076065063477 seconds\n",
      "mean of columns multiplication took: 6.07432746887207 seconds\n",
      "value counts took: 4.330781698226929 seconds\n",
      "mean of complex arithmetic ops took: 18.821117401123047 seconds\n",
      "groupby statistics took: 23.241408586502075 seconds\n",
      "join count took: 24.683266162872314 seconds\n",
      "join took: 25.168797254562378 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.168797254562378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=dask_benchmarks, name='read file')\n",
    "benchmark(count, df=dask_data, benchmarks=dask_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=dask_data, benchmarks=dask_benchmarks, name='count index length')\n",
    "benchmark(mean, df=dask_data, benchmarks=dask_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=dask_data, benchmarks=dask_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns addition')\n",
    "# benchmark(sum_columns, df=dask_data, benchmarks=dask_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns multiplication')\n",
    "# benchmark(product_columns, df=dask_data, benchmarks=dask_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=dask_data, benchmarks=dask_benchmarks, name='value counts')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=dask_data, benchmarks=dask_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, dask_data, benchmarks=dask_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, dask_data, benchmarks=dask_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (dask_data.tip_amt >= 1) & (dask_data.tip_amt <= 5)\n",
    " \n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "  \n",
    "dask_filtered = filter_data(dask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 25.63859510421753 seconds\n",
      "filtered count index length took: 23.754274368286133 seconds\n",
      "filtered mean took: 25.060559034347534 seconds\n",
      "filtered standard deviation took: 25.70417308807373 seconds\n",
      "filtered mean of columns addition took: 25.71012544631958 seconds\n",
      "filtered mean of columns multiplication took: 25.85763430595398 seconds\n",
      "filtered mean of complex arithmetic ops took: 30.063212156295776 seconds\n",
      "filtered value counts took: 25.975233793258667 seconds\n",
      "filtered groupby statistics took: 27.603911638259888 seconds\n",
      "filtered join count took: 27.22901725769043 seconds\n",
      "filtered join took: 28.791603803634644 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.791603803634644"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, dask_filtered, benchmarks=dask_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_filtered, benchmarks=dask_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_filtered, benchmarks=dask_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns addition')\n",
    "# benchmark(sum_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns multiplication')\n",
    "# benchmark(product_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_filtered, benchmarks=dask_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_filtered, benchmarks=dask_benchmarks, name='filtered groupby statistics')\n",
    " \n",
    "other = groupby_statistics(dask_filtered)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    " \n",
    "benchmark(join_count, dask_filtered, benchmarks=dask_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, dask_filtered, benchmarks=dask_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:55849</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>21.47 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55849' processes=1 threads=4, memory=21.47 GB>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "koalas_data = ks.read_parquet(F'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "\n",
    "koalas_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return ks.read_parquet(f'{DATASETS_DIR}/ks_taxi_parquet')\n",
    "  \n",
    "def count(df=None):\n",
    "    return len(df)\n",
    " \n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    " \n",
    "def mean(df):\n",
    "    return df.fare_amt.mean()\n",
    " \n",
    "def standard_deviation(df):\n",
    "    return df.fare_amt.std()\n",
    " \n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amt + df.tip_amt).mean()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def sum_columns(df):\n",
    "#     x = df.fare_amt + df.tip_amt\n",
    "#     x.to_pandas()\n",
    "#     return x\n",
    " \n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amt * df.tip_amt).mean()\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def product_columns(df):\n",
    "#     x = df.fare_amt * df.tip_amt\n",
    "#     x.to_pandas()\n",
    "#     return x\n",
    " \n",
    "def value_counts(df):\n",
    "    val_counts = df.fare_amt.value_counts()\n",
    "    val_counts.to_pandas()\n",
    "    return val_counts\n",
    "  \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "# def complicated_arithmetic_operation(df):\n",
    "#     theta_1 = df.start_lon\n",
    "#     phi_1 = df.start_lat\n",
    "#     theta_2 = df.end_lon\n",
    "#     phi_2 = df.end_lat\n",
    "#     temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "#            + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "#     ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2)\n",
    "#     ret.to_pandas()\n",
    "#     return ret\n",
    "  \n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2) \n",
    "    return ret.mean()\n",
    "  \n",
    "def groupby_statistics(df):\n",
    "    gb = df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amt': ['mean', 'std'], \n",
    "        'tip_amt': ['mean', 'std']\n",
    "      }\n",
    "    )\n",
    "    gb.to_pandas()\n",
    "    return gb\n",
    "  \n",
    "other = ks.DataFrame(groupby_statistics(koalas_data).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    " \n",
    "# The \"other.spark.hint('broadcast')\" requires the environment variable PYSPARK_PYTHON=python for it to work\n",
    "# issue: https://stackoverflow.com/questions/53252181/python-worker-failed-to-connect-back\n",
    "def join_count(df, other):\n",
    "    res = df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True)\n",
    "    return res.shape[0]\n",
    " \n",
    "# In our opinion, it doesn't make sense to compute a column and show it in memory\n",
    "# As we usually save these onto files or something similar (pagination) and this\n",
    "# method would require for all the column to be in memory\n",
    "def join_data(df, other):\n",
    "    ret = df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True)\n",
    "    ret.to_pandas()\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file took: 0.19410490989685059 seconds\n",
      "count took: 0.4697713851928711 seconds\n",
      "count index length took: 0.3832712173461914 seconds\n",
      "mean took: 0.8740348815917969 seconds\n",
      "standard deviation took: 1.2641985416412354 seconds\n",
      "mean of columns addition took: 1.6209068298339844 seconds\n",
      "mean of columns multiplication took: 1.4408636093139648 seconds\n",
      "value counts took: 11.071199655532837 seconds\n",
      "mean of complex arithmetic ops took: 21.132065057754517 seconds\n",
      "groupby statistics took: 8.751947164535522 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Uncaught exception GET /status/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='127.0.0.1:8787', method='GET', uri='/status/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yakim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tornado\\websocket.py\", line 942, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "  File \"c:\\Users\\yakim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tornado\\web.py\", line 3208, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\yakim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\bokeh\\server\\views\\ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired.\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join count took: 195.28569889068604 seconds\n",
      "join took: 379.67569041252136 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "379.67569041252136"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=koalas_benchmarks, name='read file')\n",
    "benchmark(count, df=koalas_data, benchmarks=koalas_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=koalas_data, benchmarks=koalas_benchmarks, name='count index length')\n",
    "benchmark(mean, df=koalas_data, benchmarks=koalas_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=koalas_data, benchmarks=koalas_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns addition')\n",
    "# benchmark(sum_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns multiplication')\n",
    "# benchmark(product_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=koalas_data, benchmarks=koalas_benchmarks, name='value counts')\n",
    "# benchmark(complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=koalas_data, benchmarks=koalas_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, koalas_data, benchmarks=koalas_benchmarks, name='join count', other=other)    # For this one to work, the environment variable \"PYSPARK_PYTHON\" must be set to \"python\"\n",
    "benchmark(join_data, koalas_data, benchmarks=koalas_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (koalas_data.tip_amt >= 1) & (koalas_data.tip_amt <= 5)\n",
    " \n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    " \n",
    "koalas_filtered = filter_data(koalas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 1.408207893371582 seconds\n",
      "filtered count index length took: 1.0407137870788574 seconds\n",
      "filtered mean took: 1.66477632522583 seconds\n",
      "filtered standard deviation took: 1.732065200805664 seconds\n",
      "filtered mean of columns addition took: 1.5606448650360107 seconds\n",
      "filtered mean of columns multiplication took: 1.5511305332183838 seconds\n",
      "filtered mean of complex arithmetic ops took: 10.73877215385437 seconds\n",
      "filtered value counts took: 8.656679391860962 seconds\n",
      "filtered groupby statistics took: 3.598891258239746 seconds\n",
      "filtered join count took: 217.9602336883545 seconds\n",
      "filtered join took: 409.78059339523315 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "409.78059339523315"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns addition')\n",
    "# benchmark(sum_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns multiplication')\n",
    "# benchmark(product_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered groupby statistics')\n",
    " \n",
    "other = ks.DataFrame(groupby_statistics(koalas_filtered).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "benchmark(join_count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "koalas_res_temp = get_results(koalas_benchmarks).set_index('task')\n",
    "dask_res_temp = get_results(dask_benchmarks).set_index('task')\n",
    "df = pd.concat([koalas_res_temp.duration, dask_res_temp.duration], axis=1, keys=['koalas', 'dask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../datasets/../results/koalas-benchmark-no-parquet-cache/single_node_145152\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    " \n",
    "filename = f'{DATASETS_DIR}/../results/koalas-benchmark-no-parquet-cache/single_node_' + datetime.now().strftime(\"%H%M%S\")\n",
    "print(filename)\n",
    " \n",
    "df.to_parquet(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
